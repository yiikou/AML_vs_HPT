{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook was created using version 1.0.23 of the Azure ML SDK\n",
      "You are currently using version 1.0.45 of the Azure ML SDK\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "\n",
    "print(\"This notebook was created using version 1.0.23 of the Azure ML SDK\")\n",
    "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "subscription_id = os.getenv(\"SUBSCRIPTION_ID\", default=\"52f3cf55-fed4-4f7e-9aca-f3da535a03c1\")\n",
    "resource_group = os.getenv(\"RESOURCE_GROUP\", default=\"automl_rg\")\n",
    "workspace_name = os.getenv(\"WORKSPACE_NAME\", default=\"automl_ws\")\n",
    "workspace_region = os.getenv(\"WORKSPACE_REGION\", default=\"eastus2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace configuration succeeded.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "try:\n",
    "    interactive_auth = InteractiveLoginAuthentication(tenant_id=\"1591aa04-9c2a-4144-9a04-fb8b0d506de5\")\n",
    "    ws = Workspace(subscription_id = subscription_id, \n",
    "               resource_group = resource_group, \n",
    "               workspace_name = workspace_name,\n",
    "               auth=interactive_auth)    # write the details of the workspace to a configuration file to the notebook library\n",
    "    ws.write_config()\n",
    "    print(\"Workspace configuration succeeded.\")\n",
    "except:\n",
    "    print(\"Workspace not accessible.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cpucluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"cpucluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print(\"Found existing cpucluster\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new cpucluster\")\n",
    "    \n",
    "    # Specify the configuration for the new cluster\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\",\n",
    "                                                           min_nodes=0,\n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # Create the cluster with the specified name and configuration\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "    \n",
    "    # Wait for the cluster to complete, show the output log\n",
    "    cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#dataset_name = \"defect_camel_1_2\"\n",
    "#dataset_name = \"defect_eclipse_2_0\"\n",
    "#dataset_name = \"defect_eclipse_3_0\"\n",
    "#dataset_name = \"defect_prop_2\"\n",
    "dataset_name = \"defect_xalan_2_6\"\n",
    "dataset_file_name = dataset_name+'.csv'\n",
    "dataset_path_name = os.path.join(os.getcwd(),'data/'+dataset_name+'.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True, False,  True, False, False, False,\n",
       "        True, False,  True,  True,  True,  True, False, False, False,\n",
       "        True,  True, False, False,  True, False, False, False,  True,\n",
       "        True, False,  True,  True, False, False, False, False, False,\n",
       "        True,  True,  True, False,  True,  True, False, False, False,\n",
       "        True, False,  True, False,  True,  True, False, False,  True,\n",
       "        True, False, False, False,  True,  True, False, False, False,\n",
       "        True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "        True, False,  True,  True, False, False, False, False, False,\n",
       "        True, False, False,  True, False,  True,  True,  True,  True,\n",
       "       False, False,  True, False, False,  True, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "        True,  True, False, False,  True,  True,  True, False, False,\n",
       "        True,  True, False,  True, False,  True, False,  True, False,\n",
       "        True,  True, False, False, False, False,  True, False, False,\n",
       "       False, False,  True, False,  True, False,  True, False, False,\n",
       "        True,  True, False, False,  True,  True, False,  True,  True,\n",
       "        True,  True,  True, False, False, False,  True, False, False,\n",
       "       False,  True,  True,  True,  True, False,  True,  True, False,\n",
       "       False,  True,  True,  True,  True, False,  True, False,  True,\n",
       "       False,  True, False, False,  True, False, False, False,  True,\n",
       "        True,  True,  True,  True, False, False, False,  True,  True,\n",
       "       False, False,  True,  True, False,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True, False,  True,  True, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False,  True, False,  True,  True, False,  True,  True,  True,\n",
       "       False,  True, False,  True, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False,  True, False, False,  True,\n",
       "       False, False,  True, False, False,  True, False,  True, False,\n",
       "       False,  True, False, False, False, False,  True,  True,  True,\n",
       "        True, False,  True, False, False, False,  True,  True,  True,\n",
       "        True,  True,  True, False, False, False, False,  True, False,\n",
       "        True, False,  True, False,  True, False,  True, False, False,\n",
       "        True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "       False,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True, False,  True,  True,  True, False,\n",
       "        True, False, False,  True,  True, False, False,  True,  True,\n",
       "       False,  True, False, False, False, False, False, False,  True,\n",
       "       False, False,  True, False,  True, False,  True,  True, False,\n",
       "       False,  True, False,  True, False,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True, False, False,\n",
       "        True, False, False, False, False,  True, False,  True, False,\n",
       "       False, False, False, False, False,  True, False, False, False,\n",
       "       False,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False,  True,  True,  True, False, False, False,\n",
       "       False,  True,  True, False, False, False,  True,  True, False,\n",
       "       False,  True,  True, False,  True, False, False,  True, False,\n",
       "        True, False, False,  True, False,  True, False, False,  True,\n",
       "        True, False,  True, False, False, False, False,  True,  True,\n",
       "       False, False, False,  True,  True,  True, False, False,  True,\n",
       "       False, False,  True, False,  True,  True, False,  True,  True,\n",
       "        True,  True,  True, False,  True, False, False,  True, False,\n",
       "       False,  True, False,  True, False, False, False, False,  True,\n",
       "       False,  True, False,  True, False, False,  True, False, False,\n",
       "        True, False,  True,  True, False, False, False, False,  True,\n",
       "        True, False, False,  True, False, False,  True, False, False,\n",
       "       False,  True,  True,  True, False, False, False,  True,  True,\n",
       "       False,  True, False, False,  True, False, False, False, False,\n",
       "        True,  True, False,  True, False,  True, False,  True,  True,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "       False,  True, False, False, False, False,  True,  True, False,\n",
       "        True, False, False,  True,  True, False, False, False, False,\n",
       "       False, False,  True,  True, False,  True, False,  True,  True,\n",
       "        True,  True, False, False,  True, False, False, False,  True,\n",
       "        True, False, False, False,  True, False, False,  True, False,\n",
       "       False,  True, False,  True, False, False, False, False,  True,\n",
       "        True, False, False, False, False,  True, False,  True, False,\n",
       "       False,  True, False,  True,  True, False, False, False,  True,\n",
       "       False,  True, False, False,  True,  True, False,  True, False,\n",
       "       False,  True, False,  True, False,  True, False, False, False,\n",
       "        True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "       False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "       False, False, False, False,  True,  True, False,  True, False,\n",
       "       False, False, False, False,  True, False,  True, False, False,\n",
       "       False, False,  True, False,  True, False,  True,  True,  True,\n",
       "       False,  True, False, False, False, False,  True, False,  True,\n",
       "        True,  True,  True, False, False, False,  True,  True, False,\n",
       "        True,  True,  True,  True, False,  True,  True, False, False,\n",
       "       False,  True, False, False, False,  True])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(dataset_path_name)\n",
    "x_df = df.drop(columns =['target'])\n",
    "y_df = df[['target']]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=42)\n",
    "# flatten y_train to 1d array\n",
    "y_train.values.flatten()# flatten y_train to 1d array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "885"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# AutoML start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "import pandas as pd\n",
    "from azureml.core.workspace import Workspace\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SDK version</th>\n",
       "      <td>1.0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subscription ID</th>\n",
       "      <td>52f3cf55-fed4-4f7e-9aca-f3da535a03c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Workspace</th>\n",
       "      <td>automl_ws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Group</th>\n",
       "      <td>automl_rg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>canadacentral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Project Directory</th>\n",
       "      <td>./Automl/defect_xalan_2_6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       \n",
       "SDK version        1.0.45                              \n",
       "Subscription ID    52f3cf55-fed4-4f7e-9aca-f3da535a03c1\n",
       "Workspace          automl_ws                           \n",
       "Resource Group     automl_rg                           \n",
       "Location           canadacentral                       \n",
       "Project Directory  ./Automl/defect_xalan_2_6           "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "# choose a name for the run history container in the workspace\n",
    "experiment_name = 'Automl_'+dataset_name\n",
    "# project folder\n",
    "project_folder = './Automl/'+dataset_name\n",
    "\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Project Directory'] = project_folder\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_settings = {\n",
    "    \"iteration_timeout_minutes\" : 60,\n",
    "    \"iterations\" : 100,\n",
    "    \"primary_metric\" : 'AUC_weighted',\n",
    "    \"preprocess\" : True,\n",
    "    \"verbosity\" : logging.INFO,\n",
    "    \"n_cross_validations\": 100,\n",
    "    \"validation_size\": 0.67,\n",
    "    \"enable_voting_ensemble\":False,\n",
    "    \"enable_stack_ensemble\":False,\n",
    "    \"model_explainability\":True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "# local compute \n",
    "automated_ml_config = AutoMLConfig(task = 'classification',\n",
    "                             debug_log = 'automated_ml_errors_'+dataset_name+'.log',\n",
    "                             path = project_folder,\n",
    "                             X = x_train,\n",
    "                             y = y_train.values.flatten(),\n",
    "                             **automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_561e7b85-1240-4bcc-aff3-5c674497ae0a\n",
      "Current status: DatasetFeaturization. Beginning to featurize the dataset.\n",
      "Current status: DatasetEvaluation. Gathering dataset statistics.\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetFeaturizationCompleted. Completed featurizing the dataset.\n",
      "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler LightGBM                          0:00:20       0.8089    0.8089\n",
      "         1   StandardScalerWrapper XGBoostClassifier        0:00:19       0.8185    0.8185\n",
      "         2   MaxAbsScaler SGD                               0:00:16       0.7658    0.8185\n",
      "         3   StandardScalerWrapper LightGBM                 0:00:17       0.8127    0.8185\n",
      "         4   SparseNormalizer XGBoostClassifier             0:00:18       0.8067    0.8185\n",
      "         5   MaxAbsScaler RandomForest                      0:00:20       0.8215    0.8215\n",
      "         6   MaxAbsScaler SGD                               0:00:17       0.7604    0.8215\n",
      "         7   MaxAbsScaler SGD                               0:00:19       0.7686    0.8215\n",
      "         8   StandardScalerWrapper XGBoostClassifier        0:00:19       0.8227    0.8227\n",
      "         9   MaxAbsScaler RandomForest                      0:00:19       0.8091    0.8227\n",
      "        10   MaxAbsScaler LightGBM                          0:00:17       0.8052    0.8227\n",
      "        11   MaxAbsScaler BernoulliNaiveBayes               0:00:17       0.7496    0.8227\n",
      "        12   MaxAbsScaler LightGBM                          0:00:18       0.8150    0.8227\n",
      "        13   MaxAbsScaler ExtremeRandomTrees                0:00:19       0.8064    0.8227\n",
      "        14   MaxAbsScaler ExtremeRandomTrees                0:00:25       0.7969    0.8227\n",
      "        15   MaxAbsScaler SGD                               0:00:18       0.7299    0.8227\n",
      "        16   MaxAbsScaler LightGBM                          0:00:17       0.8012    0.8227\n",
      "        17   StandardScalerWrapper BernoulliNaiveBayes      0:00:17       0.7184    0.8227\n",
      "        18   SparseNormalizer LogisticRegression            0:00:19       0.7696    0.8227\n",
      "        19   StandardScalerWrapper XGBoostClassifier        0:01:10       0.8181    0.8227\n",
      "        20   StandardScalerWrapper XGBoostClassifier        0:00:27       0.8030    0.8227\n",
      "        21   MaxAbsScaler ExtremeRandomTrees                0:01:11       0.8236    0.8236\n",
      "        22   StandardScalerWrapper XGBoostClassifier        0:00:20       0.8063    0.8236\n",
      "        23   StandardScalerWrapper XGBoostClassifier        0:00:37       0.8163    0.8236\n",
      "        24   SparseNormalizer XGBoostClassifier             0:00:21       0.8104    0.8236\n",
      "        25   MaxAbsScaler ExtremeRandomTrees                0:00:18       0.5314    0.8236\n",
      "        26   MaxAbsScaler LogisticRegression                0:00:21       0.7746    0.8236\n",
      "        27   StandardScalerWrapper XGBoostClassifier        0:00:19       0.8050    0.8236\n",
      "        28   MaxAbsScaler LightGBM                          0:00:28       0.8172    0.8236\n",
      "        29   MaxAbsScaler LightGBM                          0:00:21       0.8125    0.8236\n",
      "        30   MaxAbsScaler ExtremeRandomTrees                0:00:45       0.8197    0.8236\n",
      "        31   StandardScalerWrapper XGBoostClassifier        0:00:19       0.8112    0.8236\n",
      "        32   StandardScalerWrapper XGBoostClassifier        0:00:29       0.8158    0.8236\n",
      "        33   StandardScalerWrapper ExtremeRandomTrees       0:01:00       0.8170    0.8236\n",
      "        34   MaxAbsScaler LightGBM                          0:00:25       0.8160    0.8236\n",
      "        35   MaxAbsScaler ExtremeRandomTrees                0:00:21       0.8062    0.8236\n",
      "        36   StandardScalerWrapper XGBoostClassifier        0:00:19       0.8131    0.8236\n",
      "        37   StandardScalerWrapper XGBoostClassifier        0:00:24       0.8190    0.8236\n",
      "        38   StandardScalerWrapper XGBoostClassifier        0:00:37       0.8178    0.8236\n",
      "        39   StandardScalerWrapper LightGBM                 0:00:21       0.8179    0.8236\n",
      "        40   StandardScalerWrapper ExtremeRandomTrees       0:01:22       0.7737    0.8236\n",
      "        41   MaxAbsScaler LightGBM                          0:00:21       0.8117    0.8236\n",
      "        42   StandardScalerWrapper XGBoostClassifier        0:00:28       0.8187    0.8236\n",
      "        43   StandardScalerWrapper XGBoostClassifier        0:00:36       0.8143    0.8236\n",
      "        44   StandardScalerWrapper XGBoostClassifier        0:01:00       0.8118    0.8236\n",
      "        45   MaxAbsScaler ExtremeRandomTrees                0:01:48       0.8204    0.8236\n",
      "        46   MaxAbsScaler LogisticRegression                0:00:26       0.7319    0.8236\n",
      "        47   StandardScalerWrapper LightGBM                 0:00:27       0.8086    0.8236\n",
      "        48   StandardScalerWrapper XGBoostClassifier        0:00:22       0.8167    0.8236\n",
      "        49   MaxAbsScaler LightGBM                          0:00:21       0.8151    0.8236\n",
      "        50   MaxAbsScaler ExtremeRandomTrees                0:00:32       0.8076    0.8236\n",
      "        51   MaxAbsScaler LightGBM                          0:00:27       0.8045    0.8236\n",
      "        52   StandardScalerWrapper XGBoostClassifier        0:00:35       0.8149    0.8236\n",
      "        53   MaxAbsScaler LightGBM                          0:00:19       0.8100    0.8236\n",
      "        54   StandardScalerWrapper LightGBM                 0:00:31       0.8021    0.8236\n",
      "        55   MaxAbsScaler ExtremeRandomTrees                0:01:54       0.8073    0.8236\n",
      "        56   MaxAbsScaler LightGBM                          0:00:27       0.8089    0.8236\n",
      "        57   StandardScalerWrapper XGBoostClassifier        0:00:29       0.8184    0.8236\n",
      "        58   StandardScalerWrapper XGBoostClassifier        0:00:31       0.8155    0.8236\n",
      "        59   StandardScalerWrapper XGBoostClassifier        0:00:22       0.8174    0.8236\n",
      "        60   StandardScalerWrapper ExtremeRandomTrees       0:02:08       0.7977    0.8236\n",
      "        61   StandardScalerWrapper XGBoostClassifier        0:00:25       0.8161    0.8236\n",
      "        62   StandardScalerWrapper LightGBM                 0:00:20       0.8119    0.8236\n",
      "        63   MaxAbsScaler LightGBM                          0:00:18       0.8092    0.8236\n",
      "        64   MaxAbsScaler RandomForest                      0:00:34       0.8284    0.8284\n",
      "        65   StandardScalerWrapper RandomForest             0:02:13       0.8206    0.8284\n",
      "        66   MaxAbsScaler GradientBoosting                  0:00:32       0.8181    0.8284\n",
      "        67   StandardScalerWrapper XGBoostClassifier        0:00:40       0.8137    0.8284\n",
      "        68   StandardScalerWrapper XGBoostClassifier        0:00:48       0.8151    0.8284\n",
      "        69   MaxAbsScaler RandomForest                      0:02:16       0.8171    0.8284\n",
      "        70   MaxAbsScaler RandomForest                      0:00:25       0.8163    0.8284\n",
      "        71   StandardScalerWrapper LightGBM                 0:00:21       0.8062    0.8284\n",
      "        72   StandardScalerWrapper XGBoostClassifier        0:00:23       0.8157    0.8284\n",
      "        73   MaxAbsScaler LightGBM                          0:00:29       0.8102    0.8284\n",
      "        74   StandardScalerWrapper XGBoostClassifier        0:00:51       0.8162    0.8284\n",
      "        75   StandardScalerWrapper RandomForest             0:02:33       0.7956    0.8284\n",
      "        76   StandardScalerWrapper LightGBM                 0:00:31       0.8040    0.8284\n",
      "        77   StandardScalerWrapper XGBoostClassifier        0:00:25       0.8170    0.8284\n",
      "        78   MaxAbsScaler LightGBM                          0:00:19       0.8171    0.8284\n",
      "        79   MaxAbsScaler LightGBM                          0:00:21       0.8127    0.8284\n",
      "        80   MaxAbsScaler RandomForest                      0:01:38       0.8289    0.8289\n",
      "        81   StandardScalerWrapper LightGBM                 0:00:21       0.8159    0.8289\n",
      "        82   StandardScalerWrapper LightGBM                 0:00:26       0.8190    0.8289\n",
      "        83   MaxAbsScaler LightGBM                          0:00:20       0.8152    0.8289\n",
      "        84   MaxAbsScaler LightGBM                          0:00:19       0.8040    0.8289\n",
      "        85   TruncatedSVDWrapper RandomForest               0:00:24       0.5000    0.8289\n",
      "        86   StandardScalerWrapper LightGBM                 0:00:21       0.8180    0.8289\n",
      "        87   MaxAbsScaler LogisticRegression                0:00:30       0.7569    0.8289\n",
      "        88   MaxAbsScaler LightGBM                          0:00:25       0.8181    0.8289\n",
      "        89   StandardScalerWrapper LightGBM                 0:00:19       0.8088    0.8289\n",
      "        90   MaxAbsScaler RandomForest                      0:00:43       0.8220    0.8289\n",
      "        91   StandardScalerWrapper XGBoostClassifier        0:00:29       0.8177    0.8289\n",
      "        92   StandardScalerWrapper LightGBM                 0:00:18       0.8110    0.8289\n",
      "        93   MaxAbsScaler LightGBM                          0:00:22       0.8170    0.8289\n",
      "        94   StandardScalerWrapper XGBoostClassifier        0:00:28       0.8186    0.8289\n",
      "        95   MaxAbsScaler RandomForest                      0:00:24       0.8228    0.8289\n",
      "        96   MaxAbsScaler LightGBM                          0:00:21       0.8195    0.8289\n",
      "        97   StandardScalerWrapper XGBoostClassifier        0:00:23       0.8210    0.8289\n",
      "        98   MaxAbsScaler ExtremeRandomTrees                0:02:55       0.8184    0.8289\n",
      "        99   StandardScalerWrapper LightGBM                 0:00:28       0.8200    0.8289\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "remote_run = experiment.submit(automated_ml_config, show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_run.status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2edae5778b484290bdd8f971f515a7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 'sd…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d24cf4d7a15490d8f6c5784a31f67c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 'sd…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "from azureml.core.experiment import Experiment\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "experiment = Experiment(ws, 'Automl_defect_camel_1_2')\n",
    "\n",
    "remote_run = AutoMLRun(experiment = experiment, run_id =\"AutoML_29aecac8-d329-4ead-85e9-55db459752a2\")\n",
    "\n",
    "RunDetails(remote_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: RandomForest\n",
      "Run(Experiment: Automl_defect_xalan_2_6,\n",
      "Id: AutoML_561e7b85-1240-4bcc-aff3-5c674497ae0a_80,\n",
      "Type: None,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('datatransformer', DataTransformer(enable_feature_sweeping=None, feature_sweeping_timeout=None,\n",
      "        is_onnx_compatible=None, logger=None, observer=None, task=None)), ('MaxAbsScaler', MaxAbsScaler(copy=True)), ('RandomForestClassifier', RandomForestClassifier(bootstrap=True, class_weight=...imators=200, n_jobs=1,\n",
      "            oob_score=True, random_state=None, verbose=0, warm_start=False))])\n",
      "Y_transformer(['LabelEncoder', LabelEncoder()])\n"
     ]
    }
   ],
   "source": [
    "#iteration = 15\n",
    "#b_run, b_model = remote_run.get_output(iteration=iteration)\n",
    "\n",
    "b_run, b_model = remote_run.get_output()\n",
    "print('Algorithm: '+b_run.get_properties()['run_algorithm'])\n",
    "print(b_run)\n",
    "print(b_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='automl_ws', subscription_id='52f3cf55-fed4-4f7e-9aca-f3da535a03c1', resource_group='automl_rg'), name=AMLxalan_2_6_RandomForest, id=AMLxalan_2_6_RandomForest:1, version=1, tags={}, properties={})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelname = 'AML'+dataset_name.split('defect_')[1]+'_'+b_run.get_properties()['run_algorithm']\n",
    "b_run.register_model(model_name=modelname, model_path = 'outputs/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2fe80f097633>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWorkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'aml_model/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'defect_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mb_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'run_algorithm'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "ws = Workspace.from_config()\n",
    "b_model=Model(ws, modelname)\n",
    "model_path=model.download(target_dir=os.path.join(os.getcwd(),'aml_model/'+dataset_name.split('defect_')[1]+'/'+b_run.get_properties()['run_algorithm']), exist_ok=True)\n",
    "import pickle\n",
    "b_model = pickle.load(open(model_path, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the best model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(b_model).fit(x_test, y_test.values)\n",
    "eli5.show_weights(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc,accuracy_score,roc_auc_score,auc,roc_curve\n",
    "from sklearn.utils import resample\n",
    "sample_size = int(y_test.shape[0]*0.1)\n",
    "boot_size = 100\n",
    "auc_weighted_list=[]\n",
    "for ite in range(1,boot_size):\n",
    "    resample_x, resampel_y = resample(x_test,y_test\n",
    "                                      #, n_samples=sample_size\n",
    "                                      , replace=True, \n",
    "          random_state=ite)\n",
    "    predicted_y = b_model.predict_proba(resample_x)\n",
    "    auc_weighted=roc_auc_score(resampel_y,predicted_y[:,1],average='weighted')\n",
    "    if auc_weighted < 0.5: \n",
    "        auc_weighted = 1-auc_weighted\n",
    "    auc_weighted_list.append(auc_weighted)\n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 3)\n",
    "fig1, ax1 = plt.subplots()\n",
    "figtitle = 'AML: distribution of XGBoost performance on Eclipse_2.0'\n",
    "ax1.set_title(figtitle)\n",
    "bp_dict = ax1.boxplot(auc_weighted_list,vert=False)\n",
    "for line in bp_dict['medians']:\n",
    "    # get position data for median line\n",
    "    x, y = line.get_xydata()[1] # top of median line\n",
    "    # overlay median value\n",
    "    text(x, y, round(x,4),\n",
    "         horizontalalignment='center') # draw above, centered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model 's explanation\n",
    "Retrieve the explanation from the best_run. And explanation information includes:\n",
    "\n",
    "1. shap_values: The explanation information generated by shap lib\n",
    "2. expected_values: The expected value of the model applied to set of X_train data.\n",
    "3. overall_summary: The model level feature importance values sorted in descending order\n",
    "4. overall_imp: The feature names sorted in the same order as in overall_summary\n",
    "5. per_class_summary: The class level feature importance values sorted in descending order. Only available for the classification case\n",
    "6. per_class_imp: The feature names sorted in the same order as in per_class_summary. Only available for the classification case\n",
    "\n",
    "Note:- The retrieve_model_explanation() API only works in case AutoML has been configured with 'model_explainability' flag set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl.automlexplainer import retrieve_model_explanation\n",
    "\n",
    "shap_values, expected_values, overall_summary, overall_imp, per_class_summary, per_class_imp = \\\n",
    "    retrieve_model_explanation(b_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overall_summary)\n",
    "print(overall_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(per_class_summary)\n",
    "print(per_class_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azureml.train.automl.automlexplainer import explain_model\n",
    "\n",
    "shap_values, expected_values, overall_summary, overall_imp, per_class_summary, per_class_imp = \\\n",
    "    explain_model(b_model, x_train, x_test, features=x_train.columns)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!jupyter nbextension install --py --sys-prefix azureml.contrib.explain.model.visualize\n",
    "!jupyter nbextension enable --py --sys-prefix azureml.contrib.explain.model.visualize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overall_summary)\n",
    "print(overall_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
