{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_map = {'defect_eclipse_2_0' : \"https://raw.githubusercontent.com/yiikou/AML_vs_HPT/master/data/defect_eclipse_2_0.csv\",\n",
    "           'defect_camel_1_2':'https://raw.githubusercontent.com/yiikou/AML_vs_HPT/master/data/defect_camel_1_2.csv',\n",
    "           'defect_eclipse_3_0':'https://raw.githubusercontent.com/yiikou/AML_vs_HPT/master/data/defect_eclipse_3_0.csv',\n",
    "           'defect_prop_2':'https://raw.githubusercontent.com/yiikou/AML_vs_HPT/master/data/defect_prop_2.csv',\n",
    "           'defect_xalan_2_6':'https://raw.githubusercontent.com/yiikou/AML_vs_HPT/master/data/defect_xalan_2_6.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#dataset_name = \"defect_camel_1_2\"\n",
    "#dataset_name = \"defect_eclipse_2_0\"\n",
    "#dataset_name = \"defect_eclipse_3_0\"\n",
    "#dataset_name = \"defect_prop_2\"\n",
    "dataset_name = \"defect_xalan_2_6\"\n",
    "dataset_file_name = dataset_name+'.csv'\n",
    "dataset_path_name = os.path.join(os.getcwd(),'data/'+dataset_name+'.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/local/SAIL/jzhou/AML_vs_HPT/data/defect_xalan_2_6.csv'"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(dataset_path_name)\n",
    "x_df = df.drop(columns =['target'])\n",
    "y_df = df[['target']]\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_df, y_df, test_size=0.2, random_state=42)\n",
    "# flatten y_train to 1d array\n",
    "#y_train.values.flatten()# flatten y_train to 1d array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.45\n",
      "Turning diagnostics collection on. \n",
      "Workspace configuration succeeded.\n",
      "Found existing cpucluster\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "import logging\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n",
    "\n",
    "from azureml.telemetry import set_diagnostics_collection\n",
    "set_diagnostics_collection(send_diagnostics=True)\n",
    "\n",
    "import os\n",
    "subscription_id = os.getenv(\"SUBSCRIPTION_ID\", default=\"52f3cf55-fed4-4f7e-9aca-f3da535a03c1\")\n",
    "resource_group = os.getenv(\"RESOURCE_GROUP\", default=\"automl_rg\")\n",
    "workspace_name = os.getenv(\"WORKSPACE_NAME\", default=\"automl_ws\")\n",
    "workspace_region = os.getenv(\"WORKSPACE_REGION\", default=\"eastus2\")\n",
    "\n",
    "\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "try:\n",
    "    interactive_auth = InteractiveLoginAuthentication(tenant_id=\"1591aa04-9c2a-4144-9a04-fb8b0d506de5\")\n",
    "    ws = Workspace(subscription_id = subscription_id, \n",
    "               resource_group = resource_group, \n",
    "               workspace_name = workspace_name,\n",
    "               auth=interactive_auth)    # write the details of the workspace to a configuration file to the notebook library\n",
    "    ws.write_config()\n",
    "    print(\"Workspace configuration succeeded.\")\n",
    "except:\n",
    "    print(\"Workspace not accessible.\")\n",
    "\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"cpucluster1\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print(\"Found existing cpucluster\")\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new cpucluster\")\n",
    "    \n",
    "    # Specify the configuration for the new cluster\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\",\n",
    "                                                           min_nodes=0,\n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # Create the cluster with the specified name and configuration\n",
    "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "    \n",
    "    # Wait for the cluster to complete, show the output log\n",
    "    cpu_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Datastore"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "ds = Datastore.get(ws,datastore_name = 'workspaceblobstore')\n",
    "ds.download(target_path='your target path',\n",
    "            prefix='your prefix',\n",
    "            show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be enum\n",
    "candidate_algorithem = ['xgboost','randomforest','logistic_regression','fft']\n",
    "\n",
    "chosen_algo = 'logistic_regression'\n",
    "\n",
    "\n",
    "estimator_map  = {'xgboost':'xgb_train.py',\n",
    "                  'randomforest':'rf_train.py',\n",
    "                  'logistic_regression':'lr_train.py',\n",
    "                  'fft':'fft_train.py'    \n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azureml.train.sklearn import SKLearn\n",
    "# = SKLearn(\n",
    "from azureml.train.estimator import Estimator\n",
    "script_params = {\n",
    "        \"--split-random-seeds\":42, # seed for splitting data\n",
    "        \"--data-download-url\" : data_map[dataset_name], # data download url\n",
    "        \"--dataset-name\" :dataset_name,\n",
    "        '--output_dir': './outputs'\n",
    "}\n",
    "\n",
    "estimator = Estimator(source_directory='./estimator',\n",
    "                   script_params=script_params,\n",
    "                   compute_target=cpu_cluster,\n",
    "                   entry_script=estimator_map[chosen_algo],\n",
    "                   conda_packages=['scikit-learn','pandas','py-xgboost=0.80']\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import RandomParameterSampling\n",
    "from azureml.train.hyperdrive import choice, uniform\n",
    "\n",
    "# xgboost\n",
    "xgb_param_sampling  = RandomParameterSampling( \n",
    "    {\n",
    "        \"max-depth\":choice(range(1,10)),\n",
    "        \"eta\":uniform(0.001,6),\n",
    "        #'learning_rate': uniform(0.01,0.1),\n",
    "        'subsample': uniform(0.25,1),\n",
    "        'colsample_bytree': uniform(0.3,0.7),\n",
    "        'gamma': uniform(0,10),\n",
    "        'min_child_weight':choice(range(0,20)),\n",
    "        'n_estimators':choice(range(1,1000))\n",
    "        \n",
    "        #nrounds = sample(1:1000, size = len, replace = TRUE),\n",
    "        #max_depth = sample(1:10, replace = TRUE, size = len),\n",
    "        #eta = runif(len, min = .001, max = .6),\n",
    "        #gamma = runif(len, min = 0, max = 10),\n",
    "        #colsample_bytree = runif(len, min = .3, max = .7),\n",
    "        #min_child_weight = sample(0:20, size = len, replace = TRUE),\n",
    "        #subsample = runif(len, min = .25, max = 1)\n",
    "        \n",
    "    }\n",
    ")\n",
    "\n",
    "# randomforest\n",
    "rf_param_sampling  = RandomParameterSampling( \n",
    "    {\n",
    "        \"mtry\":choice(range(1,len(x_train.columns)))\n",
    "    }\n",
    ")\n",
    "\n",
    "# logistic regression\n",
    "lr_param_sampling  = RandomParameterSampling( \n",
    "    {\n",
    "        \"random_state\":choice(range(1,100))\n",
    "    }\n",
    ")\n",
    "\n",
    "# fft\n",
    "fft_param_sampling  = RandomParameterSampling( \n",
    "    {\n",
    "        \"alpha\":choice(range(3,10))\n",
    "    }\n",
    ")\n",
    "param_sampling_map  = {'xgboost':xgb_param_sampling,\n",
    "                  'randomforest':rf_param_sampling,\n",
    "                  'logistic_regression':lr_param_sampling,\n",
    "                  'fft':fft_param_sampling    \n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Subscription ID</th>\n",
       "      <td>52f3cf55-fed4-4f7e-9aca-f3da535a03c1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Workspace</th>\n",
       "      <td>automl_ws</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Group</th>\n",
       "      <td>automl_rg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>canadacentral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Project Directory</th>\n",
       "      <td>./HyperTuning/defect_xalan_2_6/logistic_regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Experiment Name</th>\n",
       "      <td>H_xalan_2_6_logistic_regression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     \n",
       "Subscription ID    52f3cf55-fed4-4f7e-9aca-f3da535a03c1              \n",
       "Workspace          automl_ws                                         \n",
       "Resource Group     automl_rg                                         \n",
       "Location           canadacentral                                     \n",
       "Project Directory  ./HyperTuning/defect_xalan_2_6/logistic_regression\n",
       "Experiment Name    H_xalan_2_6_logistic_regression                   "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "# choose a name for the run history container in the workspace\n",
    "experiment_name = 'H_'+dataset_name.split('defect_')[1]+\"_\"+chosen_algo\n",
    "# project folder\n",
    "project_folder = './HyperTuning/'+dataset_name+'/'+chosen_algo\n",
    "\n",
    "output = {}\n",
    "#output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Project Directory'] = project_folder\n",
    "output['Experiment Name'] = experiment_name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify primary metric & early termination policy = no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import PrimaryMetricGoal\n",
    "primary_metric_name=\"auc_weighted\" #should be exactly match the name of the metric logged by the training script\n",
    "primary_metric_goal=PrimaryMetricGoal.MAXIMIZE\n",
    "\n",
    "# Bandit policy\n",
    "# Truncation selection policy\n",
    "# Median stopping policy\n",
    "\n",
    "# No termination policy\n",
    "early_termination_policy=None\n",
    "\n",
    "\n",
    "max_total_runs=100\n",
    "max_concurrent_runs=4\n",
    "\n",
    "# Configure experiment\n",
    "\n",
    "from azureml.train.hyperdrive import HyperDriveConfig\n",
    "hyperdrive_run_config = HyperDriveConfig(estimator=estimator,\n",
    "                          hyperparameter_sampling=param_sampling_map[chosen_algo], \n",
    "                          policy=early_termination_policy, # which is None\n",
    "                          primary_metric_name=primary_metric_name, \n",
    "                          primary_metric_goal=primary_metric_goal,\n",
    "                          max_total_runs=max_total_runs,\n",
    "                          max_concurrent_runs=max_concurrent_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit experiment or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.experiment import Experiment\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "hyperdrive_run = experiment.submit(hyperdrive_run_config,tags={'Algorithm':chosen_algo})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>H_eclipse_2_0_xgboost</td><td>H_eclipse_2_0_xgboost_1561759477871</td><td>hyperdrive</td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/52f3cf55-fed4-4f7e-9aca-f3da535a03c1/resourceGroups/automl_rg/providers/Microsoft.MachineLearningServices/workspaces/automl_ws/experiments/H_eclipse_2_0_xgboost/runs/H_eclipse_2_0_xgboost_1561759477871\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: H_eclipse_2_0_xgboost,\n",
       "Id: H_eclipse_2_0_xgboost_1561759477871,\n",
       "Type: hyperdrive,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperdrive_run "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch a specific run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import HyperDriveRun\n",
    "from azureml.core.experiment import Experiment\n",
    "experiment_name='H_camel_1_2_randomforest'\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "hyperdrive_run = HyperDriveRun(experiment = experiment, run_id =\"H_camel_1_2_randomforest_1561751966406\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733acad0aa504cb7a2ec43a748c79a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "#print(hyperdrive_run.get_details())\n",
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: logistic_regression\n",
      "{'max_depth': 5, 'eta': 5.30715931194066, 'silent': 1, 'subsample': 0.830657629802624, 'colsample_bytree': 0.584971596458506, 'gamma': 6.09027908137873, 'min_child_weight': 2, 'n_estimators': 246}\n",
      "0.8442904180828843\n"
     ]
    }
   ],
   "source": [
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "print('Algorithm: '+chosen_algo)\n",
    "print(best_run_metrics['hyper_param'])\n",
    "print(best_run_metrics['auc_weighted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register model to workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = 'HYPER_'+dataset_name.split('defect_')[1]+'_'+chosen_algo\n",
    "model = best_run.register_model(model_name =modelname, model_path = 'outputs/model.pkl')\n",
    "print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "ws = Workspace.from_config()\n",
    "model=Model(ws, modelname)\n",
    "model_path=model.download(target_dir=os.path.join(os.getcwd(),'hyper_model/'+dataset_name.split('defect_')[1]+'/'+chosen_algo), exist_ok=True)\n",
    "import pickle\n",
    "import xgboost\n",
    "b_model = pickle.load(open(model_path, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate performance (AUC_weighted) on test dataset using Bootstrap approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "perm = PermutationImportance(b_model).fit(x_test, y_test.values)\n",
    "eli5.show_weights(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc,accuracy_score,roc_auc_score,auc,roc_curve\n",
    "from sklearn.utils import resample\n",
    "sample_size = int(y_test.shape[0]*0.1)\n",
    "boot_size = 100\n",
    "auc_weighted_list=[]\n",
    "for ite in range(1,boot_size):\n",
    "    resample_x, resampel_y = resample(x_test,y_test\n",
    "                                      #, n_samples=sample_size\n",
    "                                      , replace=True, \n",
    "          random_state=ite)\n",
    "    predicted_y = b_model.predict_proba(resample_x)\n",
    "    auc_weighted=roc_auc_score(resampel_y,predicted_y[:,1],average='weighted')\n",
    "    if auc_weighted < 0.5: \n",
    "        auc_weighted = 1-auc_weighted\n",
    "    auc_weighted_list.append(auc_weighted)\n",
    "    #print(auc_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (5, 3)\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('HT: distribution of XGBoost performance on Eclipse_2.0')\n",
    "bp_dict = ax1.boxplot(auc_weighted_list,vert=False)\n",
    "for line in bp_dict['medians']:\n",
    "    # get position data for median line\n",
    "    x, y = line.get_xydata()[1] # top of median line\n",
    "    # overlay median value\n",
    "    text(x, y, round(x,4),\n",
    "         horizontalalignment='center') # draw above, centered"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#fig2, ax2 = plt.subplots(1,1,figsize=5)\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 10)\n",
    "plot_importance(hyper_xgb_model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "children = list(hyperdrive_run.get_children())\n",
    "metricslist = {}\n",
    "for run in children:\n",
    "    #properties = run.get_properties()\n",
    "    #metrics = {k: v for k, v in run.get_metrics().items() if isinstance(v, float)}\n",
    "    if 'Hyper parameter' not in run.get_metrics().keys():\n",
    "        continue\n",
    "    d = run.get_metrics()['Hyper parameter']\n",
    "    d['auc_weighted'] = run.get_metrics()['auc_weighted']\n",
    "    metricslist[int(run.get_details() ['runId'].split('_')[-1])] = d\n",
    "\n",
    "rundata = pd.DataFrame(metricslist).sort_index(1).transpose()\n",
    "rundata\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import pandas.plotting.parallel_coordinates as parallel_coordinates\n",
    "plt.figure()\n",
    "plotdata = rundata\n",
    "plotdata['auc_weighted_cut'] = pd.cut(plotdata['auc_weighted'], (np.linspace(start=80, stop=90, num=15)/100).tolist())\n",
    "#plotdata['auc_weighted_cut'] = plotdata['auc_weighted']\n",
    "pd.plotting.parallel_coordinates(\n",
    "    plotdata[['auc_weighted_cut','colsample_bytree', 'learning_rate','max_depth', 'subsample']] \n",
    "    ,'auc_weighted_cut'\n",
    "    , colormap='Blues' )\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def parallel_coordinates(frame, class_column, cols=None, ax=None, color=None,\n",
    "                     use_columns=False, xticks=None, colormap=None,\n",
    "                     **kwds):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib as mpl\n",
    "\n",
    "    n = len(frame)\n",
    "    class_col = frame[class_column]\n",
    "    class_min = np.amin(class_col)\n",
    "    class_max = np.amax(class_col)\n",
    "\n",
    "    if cols is None:\n",
    "        df = frame.drop(class_column, axis=1)\n",
    "    else:\n",
    "        df = frame[cols]\n",
    "\n",
    "    used_legends = set([])\n",
    "\n",
    "    ncols = len(df.columns)\n",
    "\n",
    "    # determine values to use for xticks\n",
    "    if use_columns is True:\n",
    "        if not np.all(np.isreal(list(df.columns))):\n",
    "            raise ValueError('Columns must be numeric to be used as xticks')\n",
    "        x = df.columns\n",
    "    elif xticks is not None:\n",
    "        if not np.all(np.isreal(xticks)):\n",
    "            raise ValueError('xticks specified must be numeric')\n",
    "        elif len(xticks) != ncols:\n",
    "            raise ValueError('Length of xticks must match number of columns')\n",
    "        x = xticks\n",
    "    else:\n",
    "        x = range(ncols)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = plt.gca()\n",
    "\n",
    "    Colorm = plt.get_cmap(colormap)\n",
    "\n",
    "    for i in range(n):\n",
    "        y = df.iloc[i].values\n",
    "        kls = class_col.iat[i]\n",
    "        ax.plot(x, y, color=Colorm((kls - class_min)/(class_max-class_min)), **kwds)\n",
    "\n",
    "    for i in x:\n",
    "        ax.axvline(i, linewidth=1, color='black')\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(df.columns)\n",
    "    ax.set_xlim(x[0], x[-1])\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid()\n",
    "\n",
    "    bounds = np.linspace(class_min,class_max,10)\n",
    "    cax,_ = mpl.colorbar.make_axes(ax)\n",
    "    cb = mpl.colorbar.ColorbarBase(cax, cmap=Colorm, spacing='proportional', ticks=bounds, boundaries=bounds, format='%.2f')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "parallel_coordinates(rundata, 'auc_weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
